### Predict Employee Attrition
### Upload Respective Libraries and Data from Excel
library(readxl)
library(plyr)
library(dplyr)
library(ggplot2)
library(caret)
library(rattle)
library(magrittr) 
library(rpart, quietly = TRUE)
library(kernlab, quietly = TRUE)
library(e1071)
library(randomForest)
library(rfviz)
library(tcltk)
project_df = read_excel("ALPHATERM.xlsx")
View(project_df)

### Defining variables and different df's 
var = project_df[,c(5,8,13,15:17,19,21,26,27)] 
var_factor = var %>%
  mutate_if(is.character, as.factor) %>%
  select(everything())
status = project_df[,13]

### Some Data Insights
as.data.frame(table(project_df[,9])) # Number of terminations since 2018
ggplot() + geom_bar(aes(y = ..count.., x=as.factor(Department.Code), 
                        fill = as.factor(Employee.Status)), 
                    data=project_df, position = position_stack()) # Hist. of Active/Inactive by Dept. 
Terms = as.data.frame(project_df %>%
                        filter(Employee.Status=="Inactive")) # All terminated employees

featurePlot(x=project_df[,13:14], y=status_factor, plot = "density", 
            auto.key = list(columns = 2)) 
featurePlot(x=project_df[,13:14], y=status_factor, plot = "box", auto.key = list(columns = 2)) # Box plot of the same thing as above


### Partitioning the Data into Training and Test Sets
set.seed(69)
n = nrow(project_df)
t_sample = sample(c(1:1754), floor(0.75*length(c(1:1754))), replace=FALSE) # Using 75% for training
a_sample = sample(c(1755:n), floor(0.75*length(c(1755:n))), replace=FALSE) 

var_train = var[c(t_sample,a_sample), ]
var_test = var[-c(t_sample,a_sample), ]
var_factor_train = var_factor[c(t_sample,a_sample), ]
var_factor_test = var_factor[-c(t_sample,a_sample), ]

### Random Forest Model
rf_project = randomForest(var_factor_train$Employee.Status ~ .,
                                         data=var_factor_train,
                                         ntree=500, 
                                         importance=TRUE)
rf_project

# See error based on number of trees
error_trees = data.frame(Trees=rep(1:nrow(rf_project$err.rate), times=3),
                            Type=rep(c("OOB", "Active", "Inactive"), each=nrow(rf_project$err.rate)),
                            Error=c(rf_project$err.rate[,"OOB"],
                                    rf_project$err.rate[,"Active"],
                                    rf_project$err.rate[,"Inactive"]))
ggplot(data=error_trees, aes(x=Trees, y=Error)) + geom_line(aes(color=Type))

# Use model to predict categorization - Test data
rf_predict = predict(rf_project, newdata=var_factor_test, type="class")
table(var_factor_test$Employee.Status, rf_predict,
      dnn=c("Actual", "Predicted"))

error_func <- function(actual, predict)
{
  x <- table(actual, predict)
  nrows <- nrow(x)
  tble <- cbind(x/length(actual),
               Error=sapply(1:nrows,
                            function(r) round(sum(x[r,-r])/sum(x[r,]), 2)))
  names(attr(tbl, "dimnames")) <- c("Actual", "Predicted")
  return(tbl)
}

rf_error = error_func(var_factor_test$Employee.Status, rf_predict)
round(rf_error, 3)

# Find AUC and AUC confidence interval
rf_auc = pROC::roc(rf_project$y, as.numeric(rf_project$predicted)) 
rf_auc_ci = pROC::ci.auc(rf_project$y, as.numeric(rf_project$predicted)) rf_imp = round(randomForest::importance(rf_project), 2) 
rf_imp[order(rf_imp[,2], decreasing=TRUE),]

### Decision Tree Model 
dt_project = rpart(var_factor_train$Employee.Status ~ ., 
               data=var_factor_train,
               method="class",
               parms=list(split="information"),
               control=rpart.control(usesurrogate=0, 
                                     maxsurrogate=0))
printcp(dt_project)
fancyRpartPlot(dt_project, main="Attrition Decision Tree") 

# Use model to predict categorization - Test data
dt_predict = predict(dt_project, newdata=var_factor_test, type="class")
table(var_factor_test$Employee.Status, dt_predict,
      dnn=c("Actual", "Predicted"))

dt_error = error_func(var_factor_test$Employee.Status, dt_predict)
round(dt_error, 3)

### Subsetting Terminations
terms = subset(project_df, project_df$Employee.Status == 'Inactive')
var_terms = terms[,c(5,8,10,13,15:17,19,21,26,27)]
var_terms = var_terms %>%
  mutate_if(is.character, as.factor) %>%
  select(everything()) # Variables left categorical are factorized

### Sampling for Test and Training Data
set.seed(16)
t = nrow(terms)
term_sample = sort(sample(c(1:t), floor(0.75*length(c(1:t))), replace=FALSE))
term_train = var_terms[term_sample, ]
term_test = var_terms[-term_sample, ]

### Random Forest - Predicting termination reason
rf_terms = randomForest(term_train$Termination.Reason ~., 
                        data = term_train, 
                        ntree=500,
                        importance=TRUE)
rf_terms

# Error on Terms
term_predict = predict(rf_terms, newdata=term_test, type="class")
table(term_test$Termination.Reason, term_predict,
      dnn=c("Actual", "Predicted"))

term_error = error_func(term_test$Termination.Reason, term_predict)
round(term_error, 3)

### Decision Tree - Predicting termination reason
dt_terms = rpart(term_train$Termination.Reason ~ ., 
                 data=term_train,
                 method="class",
                 parms=list(split="information"),
                 control=rpart.control(usesurrogate=0, 
                                       maxsurrogate=0))
printcp(dt_terms)
fancyRpartPlot(dt_terms, main="Termination Reason Decision Tree")

# Use model to predict categorization - Test data
dt_term_predict = predict(dt_terms, newdata=term_test, type="class")
table(term_test$Termination.Reason, dt_term_predict,
      dnn=c("Actual", "Predicted"))

dt_error = error_func(term_test$Termination.Reason, dt_term_predict)
round(dt_error, 3)
